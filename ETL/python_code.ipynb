{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(r\"\\CSV\\RoutineEcho_CompleteSet.csv\",) #nrows=50000)\n",
    "\n",
    "########################\n",
    "# Cleaning\n",
    "########################\n",
    "\n",
    "df['StudyDate'] = pd.to_datetime(df.StudyDate, format='%Y-%m-%d')\n",
    "\n",
    "# Filtering out studies by date\n",
    "bottom_date = datetime.datetime(2016, 6, 1)\n",
    "cond_1 = df.StudyDate >= bottom_date\n",
    "\n",
    "# Filtering by status\n",
    "cond_2 = (df.StudyStatus == 'Final') | (df.StudyStatus == 'Revised')\n",
    "\n",
    "# Building clean dataset\n",
    "df = df[cond_1 & cond_2]\n",
    "\n",
    "##############################\n",
    "# Checking for missing order IDs\n",
    "##############################\n",
    "null_IDs = df.OrderID.isnull()\n",
    "random_vector = np.arange(0,sum(null_IDs),1,dtype=int)\n",
    "list_missing_ord_id = [str(x) + 'MISS' for x in random_vector]\n",
    "\n",
    "df.loc[null_IDs, 'OrderID'] = list_missing_ord_id\n",
    "#[1]\n",
    "\n",
    "\n",
    "#We are trying to map a multi-dimensional array into one cell location\n",
    "\n",
    "#print(len(df.OrderID))\n",
    "#print(len(list_missing_ord_id))\n",
    "\n",
    "\n",
    "##############################\n",
    "# Mod. Duplicates Order ID\n",
    "##############################\n",
    "\n",
    "flag_duplicates = df.OrderID.duplicated()\n",
    "curr_order_id = list(df.OrderID[flag_duplicates])\n",
    "new_order_id = [str(x) + \"_DUP\" for x in curr_order_id]\n",
    "df.loc[flag_duplicates, 'OrderID'] = new_order_id\n",
    "\n",
    "##############################\n",
    "# Data restructuring\n",
    "##############################\n",
    "s_keys = df.OrderID\n",
    "\n",
    "dict_long = {}\n",
    "dict_long['PatientID'] = []\n",
    "dict_long['PatientID2'] = []\n",
    "dict_long['StudyDate'] = []\n",
    "dict_long['OrderID'] = []\n",
    "dict_long['Findings_Name'] = []\n",
    "dict_long['Findings_Value'] = []\n",
    "\n",
    "key_columns = ['PatientID', 'PatientID2', 'StudyDate', 'OrderID']\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "other_columns = []\n",
    "for c_col in list(df.columns):\n",
    "    if c_col not in key_columns:\n",
    "        if c_col[:8] == 'FINDINGS':\n",
    "            other_columns.append(c_col)\n",
    "\n",
    "for i, key in enumerate(s_keys):\n",
    "    \n",
    "    df_loc = df[df.OrderID == key]\n",
    "    \n",
    "    PAT_ID = df_loc.PatientID.to_numpy()[0]\n",
    "    PAT_ID2 = df_loc.PatientID2.to_numpy()[0]\n",
    "    ST_DATE = df_loc.StudyDate.to_numpy()[0]\n",
    "    ORD_ID = df_loc.OrderID.to_numpy()[0]\n",
    "    \n",
    "    for c_col in other_columns:\n",
    "        if ~df_loc[c_col].isnull().iloc[0]:\n",
    "            dict_long['PatientID'].append(PAT_ID)\n",
    "            dict_long['PatientID2'].append(PAT_ID2)\n",
    "            dict_long['StudyDate'].append(ST_DATE)\n",
    "            dict_long['OrderID'].append(ORD_ID)\n",
    "            dict_long['Findings_Name'].append(c_col)\n",
    "            dict_long['Findings_Value'].append(df_loc[c_col].to_numpy()[0])\n",
    "            \n",
    "    if i%100 == 0: \n",
    "        print('Done with {0} order IDs'.format(i))\n",
    "        elapsed_time = time.time() - start_time\n",
    "        number_files_missing = len(s_keys) - i\n",
    "        missing_time = elapsed_time*number_files_missing/(i+1)\n",
    "        print('Missing time: {0:.1f} minutes'.format(missing_time/60))\n",
    "        \n",
    "\n",
    "# Converting output into a dataframe\n",
    "df_out = pd.DataFrame(dict_long)\n",
    "\n",
    "df_out.to_csv(r'CSV\\RoutineEcho_ReshapedLong.csv')\n",
    "\n",
    "##############################\n",
    "# Finding columns\n",
    "##############################\n",
    "base_string = \"mitral regurgitation\"\n",
    "charac_org = [\"No evidence of\", \"Mild\", \"Mild to moderate\", \"Moderate\", \"Moderate to severe\", \"Severe\", \"Unable to assess severity of\"]\n",
    "char_rec = [\"A trace of\", \"Clinically insignificant\"]\n",
    "charac = charac_org + char_rec\n",
    "\n",
    "dict_var = {}\n",
    "dict_var['OrderID'] = []\n",
    "dict_var['MR_Severity'] = []\n",
    "\n",
    "for c in charac:\n",
    "    \n",
    "    print(c)\n",
    "    \n",
    "    search_string = c + \" \" + base_string\n",
    "    flags = df_out['Findings_Value'].str.contains(search_string, case=True)\n",
    "        \n",
    "    print(df_out[flags].Findings_Value.iloc[0:10])\n",
    "    ord_id = list(df_out[flags].OrderID)\n",
    "    if c in char_rec:\n",
    "        severity = [\"Mild\"] * len(ord_id)\n",
    "    else:\n",
    "        severity = [c] * len(ord_id)\n",
    "    for i, _ in enumerate(ord_id):\n",
    "        dict_var['OrderID'].append(ord_id[i])\n",
    "        dict_var['MR_Severity'].append(severity[i])\n",
    "\n",
    "# Creating variable dictionary\n",
    "df_var = pd.DataFrame(dict_var)\n",
    "\n",
    "# Created a new variable\n",
    "## Code for the new variable ###\n",
    "# Let's say the new variable is in df_var_2\n",
    "\n",
    "#df_var = df_var.merge(df_var_2, on='OrderID', how='outer')\n",
    "\n",
    "# Create the output dataframe\n",
    "df_export = df[key_columns].merge(df_var, on='OrderID', how='left')\n",
    "df_export.to_csv(r\"S:\\Data Team\\NASIR\\Routine Echo\\Data\\CSV\\Test\\test_out.csv\")\n",
    "\n",
    "## Checks\n",
    "# unique_order_IDs = len(df_out[flags].OrderID.unique())\n",
    "# unique_entries = sum(flags)\n",
    "# unique_patients = len(df_out[flags].PatientID.unique())\n",
    "# lu = df_out[flags].Findings_Name.unique()\n",
    "# sum(df_out[flags].Findings_Name == lu[0])\n",
    "# sum(df_out[flags].Findings_Name == lu[1])\n",
    "# sum(df_out[flags].Findings_Name == lu[2])\n",
    "\n",
    " #usecols=list(np.arange(0,10,1,dtype=int)))\n",
    "\n",
    "#df = dfc\n",
    "\n",
    "#print(dfc.head(3))\n",
    "#print(dfc.tail(3))\n",
    "\n",
    "#dfc.columns    //Read each column header\n",
    "#print(dfc.columns)\n",
    "#dfc['OrderID'] ...//Read each column\n",
    "#print(dfc['OrderID'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
