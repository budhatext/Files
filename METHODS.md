
# Building A Novel AI-Driven Echocardiography Data Pipeline: Findings from a Large Learning Health System
Budhaditya Bose, Sara A. Butt, Hassan B. Arshad, Charlie C. Nicolas, Rakesh Gullapelli, Nwabunie Nwana, Zulqarnain Javed, Izza Shahid, Payam Pournazari, Kershaw Patel, M.A. Chamsi Pasha, Stephen H. Little, Nadeen S. Faza, Stephen Jones, M.A. Cainzos, Sadeer Al-Kindi, Jean Michel Saad, William Zoghbi, Sherif F. Nagueh, Khurram Nasir,
Building A Novel AI-Driven Echocardiography Data Pipeline: Findings from a Large Learning Health System,
Journal of the American Society of Echocardiography,
2024,
,
ISSN 0894-7317,
https://doi.org/10.1016/j.echo.2024.05.018.
(https://www.sciencedirect.com/science/article/pii/S0894731724002888)

# ETL PIPELINE 
We extracted semi-structured data, which is defined as data that is partially organized, and does not follow the format of relational databases without a fixed schema, in table format from cardiovascular reporting software primarily used to capture the measurements and 2D echo findings for 92,307 patients undergoing a total of 175,399 echo studies at one of the 8 HM outpatient, inpatient, emergency department locations between 1st June 2016 and 31st May 2022 as our full dataset (FD). The semi-structured excel format dataset consisted of  5,272 columns without defined labels from which we identified 772 columns for qualitative variables. Among 772 columns, we identified 154 columns for mitral valve with qualitative statements that might contain severities for mitral regurgitation and mitral stenosis, 85 columns for aortic valve that might contain severities for aortic regurgitation, aortic stenosis, and flow gradient across aortic stenosis, 56 columns with qualitative statements for ejection fraction and 13 columns with statements for diastolic function.
[Click this link to view these columns](https://github.com/budhatext/Files/blob/main/ETL/undefined_columns_names.xlsx).

Applied exclusion criteria included patients less than 18 years of age and echocardiography readings that were incomplete or done at outside institutions (i.e., echocardiography statuses that included scanned, outside facility review, outside review, preread complete, research, outside study, no charge report, unread, aborted exam)   

## Development and validation 
![Figure 1](https://github.com/budhatext/Files/blob/main/ETL/Figure1.png)
Figure 1: Steps for ETL process development and data quality assessment using NLP and ML techniques.

We split the FD into 4:1 for development and validation of ETL and data quality assessment using NLP and ML algorithms. The development dataset (DD) consisted of 73,986 patients undergoing a total of 136,548 echo studies between 1st June 2016 – 31St March 2021 and validation dataset (VD) comprised of 28,035 patients undergoing 38,851 echo studies between 1st April 2021 – 31st May 2022 (Figure 1). We reviewed approximately 772 and 4,500 de-identified columns from DD with clinically relevant findings (i.e., one or more sentences) and accompanying numeric values respectively. This study was approved by the HM institutional review board.

## Echo measurements
 The primary outcomes of interest were mitral regurgitation (MR), mitral stenosis (MS), aortic regurgitation (AR), aortic stenosis (AS), flow gradient across aortic stenosis (FG), diastolic dysfunction (DF) and left ventricular ejection fraction (LVEF). Out of 154 columns of mitral valve, 49 and 30 columns were identified for MR and MS respectively. Out of 85 columns of aortic valve, 24,31 and 10 columns were identified for AR, AS and FG respectively. We identified and labeled the severity of the outcomes as follows: mild, mild-to-moderate, moderate, moderate-to-severe, severe, indeterminate and normal for MR,MS,AR,AS; low-flow-low-gradient, paradoxical low-flow-low-gradient, and normal cases for FG; grade I,II,III and normal cases for DF and numeric values, range of values, qualitative values for LVEF. Moreover, other identified findings include the presence and absence of ‘mitraclip’ and ‘prosthetic’ valve for mitral valve and aortic valve respectively.
 
## Data transformation 
We incorporated  the DD echo dataset into the Microsoft SQL Server Studio V18.8 after having transformed the data to one single findings column from 772 columns using our [developed code in Python](https://github.com/budhatext/Files/blob/main/ETL/python_code.ipynb) (Jupyter 6.1.4) linking it with the de-identified unique patient, echo measurement date and echo report identifier. These columns essentially consisted of sentences or chunks of sentences of varying length. Our cardiologists and data engineer defined a ‘lexicon’ consisting of ‘basestring’ and corresponding ‘keywords’ consisting of variant phrasings, synonyms, shortened form of words, multi-word terms, abbreviations, and misspellings for each of these 7 outcome variables and associated severities. 

[Data labeling rule](https://github.com/budhatext/echocardiography/blob/main/ETL/Flowchart%201.1.pptx) has been finalized after iteratively reviewing 80 % report descriptions until a sentence level consensus was reached among three cardiologists based on clinical experience and adjudication by a senior cardiologist for [discordant cases](https://github.com/budhatext/Files/blob/main/ETL/cases_discordant_eg.xlsx).

The [‘lexicon’](https://github.com/budhatext/Files/blob/main/ETL/Lexicon.docx) and data labelling rule served as the main criteria for labelling severities for MR,MS,AR,AS,FG, DF and LVEF),the presence of Mitra clip, prosthetic valve for mitral and aortic valve or normal cases for others leveraging the defined lexicon. 

We developed ['regular expression'](https://github.com/budhatext/Files/blob/main/ETL/echo_pipeline.sql) pattern matching i.e. sequences of characters forming the search pattern in Structure Query Language transformation logic (SQL) to abstract ‘base string’ along with associated severities from the textual description per the established  data labeling rule. We also used negation terms referring to the lexicon such as ‘No MR’ or ‘No Mitral Regurgitation or ‘Paravalvular MR’ or ‘Mitraclip’ and secondary outcomes to label the normal cohort. These regular expressions are also developed to handle spelling mistakes, space checks, punctuations, case sensitive matches, chunks of free-texts and group of words. We have chosen the most severe finding if a patient had multiple severities reported on the study date and as of the latest status of a patient severity. We have consistently assigned severity priority in the following order for MR,MS,AR and AS: severe>moderate to severe>moderate>mild to moderate>mild>trace, grade III> grade II>grade I> normal for DF, Paradoxical low flow low gradient>low flow low gradient for flow gradient, numeric LVEF>  range LVEF> qualitative LVEF for LVEF. 

For example, if a patient had ‘severe mitral regurgitation’ and ‘mild to moderate mitral regurgitation’ appearing on the same date for an echo report then on such case the final severity labelled is ‘severe mitral regurgitation’. However, if a patient had a ‘severe mitral regurgitation on a prior date (e.g., 12th January 2022) and ‘moderate to severe mitral regurgitation’ on the latest date (e.g., 1st March 2022) then the severity is labelled of latest date i.e., ‘moderate to severe mitral regurgitation’.

LVEF data was available as numeric values (e.g., 75, 40.5), range (e.g., 40-50, 45-55) and qualitative (for e.g., mild, mildly depressed, hyperdynamic). We observed LVEF ranges with 4 different band types: interval of four (e.g., 60-64), five (e.g., 50-55), nine (e.g., 50-59) and ten (e.g., 50-60). For all these cases, numeric values were generated from range values by computing the mean of the upper and lower bounds of the range. For e.g., for a range of (40-45), (50-60),(55-60) a value of 42.5,55,57.5 have been assigned, respectively. The text descriptions are converted into numeric values using previous literary evidence. If a patient had numeric LVEF, range of LVEF and qualitative LVEF mentioned on the same echo report then the final label is as of numeric LVEF. The patient level final assignment of ejection fraction is of the latest date on which the LVEF is available. The [descriptive statistics](https://github.com/budhatext/echocardiography/blob/main/Results/Table_1_supplementary.docx) of extracted data is made available here.

## Data quality improvement
We improved the quality of labels by improving the regular expression SQL code. We randomly selected and manually tested 1,352 (2%) echo files from DD (i.e., 73,986 echo reports between 1st June 2016 – 31st March 2021) by identifying the missed logic contributing to the false positives (FP) and false negatives (FN). This process is repeated over 7 iterations and computed precision, recall, F1 score (i.e., harmonic mean between precision and recall), and accuracy as performance metrics. For each labelled outcome and expected data label  pair, true positive (TP) was defined as identical severities, diastolic function, flow gradient and/or LVEF between the labelled outcome and description following the data labelling rule. FN was defined as presence of severity, diastolic function, flow gradient and/or LVEF on manual echo review but incorrect labelled outcome per the data labelling rule. FP was defined as cases where the severity, diastolic function, flow gradient and/or LVEF are absent on manual echo review but were present in the labelled outcome. True negative (TN) was defined as the absence of severities (i.e., normal cases) in the manual echo review and the labelled outcome. [Click to view the manual validation results](https://github.com/budhatext/Files/blob/main/Results/manual_validation.docx)

## Feature engineering 
We further automated the validation check of the accuracy of SQL based regular expression in labelling the final severity, FG, DF and/or LVEF by selecting 28,035 VD descriptions used for final assignment of these measures. We achieved this by employing feature engineering using NLTK package for Natural Language Processing (NLP)  in python (Jupyter 6.1.4), with the following steps:-
### Text pre-processing and tokenization:
This involved removal of extra spaces, non-digit, non-word characters, single characters and English stop words (i.e., common and usually unimportant words such as “is”, “and” ,“the”) and conversion into an indexed format consisting of tokens or words. This aided in reduction of the number of features in the dataset and allows the algorithm to focus on meaningful elements of the text.
### Text vectorization:
This step involved conversion of the pre-processed texts into a two-dimensional array of numeric vectors where rows are instances of an echo and column are features (i.e., tokens) using count Vectorizer in python (default setting). It counted the frequency of words and built the sparse matrix-vector using bag-of-words (BOW).
### Feature extraction:
Features were extracted using Term Frequency-Inverse Document Frequency (TF-IDF). In our research context, TF in the number of times a word appears in the final descriptions based on which the  lexicon derived data labels  have been labelled. The IDF is the natural logarithm of total number of final descriptions, divided by the number of descriptions with a given term in it. The TF-IDF is the product of the term frequency and the inverse document frequency scaling our vector based on numeric representation of word importance.
We used synthetic minority oversampling technique (SMOTE) to oversample the minority class by generating synthetic examples using interpolation to overcome over fitting problems in machine learning and edited nearest neighbor algorithm (ENN) removed the redundant sample to handle the noise generated by SMOTE. Therefore SMOTE- ENN produces class balanced data that was used to model the machine learning algorithms.
['Click to access more details on NLP and ML requirements'](https://github.com/budhatext/Files/blob/main/Machine%20Learning/Machine_learning_details.docx)

## Machine learning modeling
The accuracy of the Regular expression derived data labels is validated using the [ML models](https://github.com/budhatext/Files/blob/main/Results/Machine_learning_results.docx) leveraging entire VD bypassing the time expensive manual validation which already achieved 100% sensitivity,specificity,F1 and accuracy on 1,352 reports from DD. The nature of qualitative statements is similar in both DD and VD except  that timelines are different and hence we did not perform manual validation on VD. We performed 5-fold stratified cross-validation (K-stratified CV) on the SMOTE+ENN sampled dataset using support vector machine (SVM) , extreme gradient boosting (XGBoost) and random forest (RF) ML models to learn the relationship between lexicon derived data labels generated by SQL based regular expression and TF-IDF generated features and compared their performances.
[Click to access more details on ML models details and python codes.](https://github.com/budhatext/Files/tree/main/Machine%20Learning)

## Data harmonization
We deployed the FD collective of 1st June 2016 – 31st May 2022 after having linked to  the existing HM CVD Datawarehouse.  The extracted data was linked to the existing HM CVD Datawarehouse (CDW) database which houses patient demographics, clinical encounters, medical/surgical procedures, vital signs, laboratory data, comorbidities, clinical diagnosis, medication use, social determinants of health (SDOH) data and health outcomes (hospitalizations, principal diagnosis of hospitalization, length of inpatient stay, major adverse cardiovascular events (MACE), heart failure (HF), myocardial infraction (MI), stroke, angina at inpatient, patient alive status and principal diagnosis of emergency visits. The SQL batch job has been automated to perform this job semi-annually to update the database over time.

## Data validation 
A total of 1,352 echo reports were used to undergo manual validation of the data over multiple iterations. Through iterative refinement of regular expression patterns, we observed a notable improvement in precision, F-1 score, and accuracy across different parameters. Initially, for almost all parameters except diastolic function the true positive (TP) rates were lower, indicating room for improvement. However, as iterations progressed, there was a marked increase in TP rates and a corresponding enhancement in precision, recall, F1 Score, and accuracy.The [Fleiss’s kappa’s score](https://github.com/budhatext/Files/blob/main/Results/Fleiss_Kappa_score.docx) among three cardiologists varies between 0.81-0.91 suggesting strong inter-rater agreement in approving the lexicon.

## Data quality 
The Machine learning models were trained and tested over the balanced validation dataset achieved a high sensitivity,specificity,F1-score, and accuracy in data labelling as per the defined lexicon and data labelling rule thereby elucidating the robustness of regular expressions in data label
