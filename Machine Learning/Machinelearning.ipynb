{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb254e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc \n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, make_scorer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.corpus import stopwords  \n",
    "\n",
    "# Downloading NLTK punkt package\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Establishing SQL connection\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=SERVER;'\n",
    "                      'Database=DB;'\n",
    "                      'user=USER;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "# Reading data from SQL server\n",
    "sql_query = pd.read_sql_query('SELECT * FROM ECHO_DATABASE', conn)\n",
    "df = pd.DataFrame(sql_query, columns=['Findings_Value', 'SEVERITY'])\n",
    "print(df)\n",
    "\n",
    "# Data preprocessing: Removing numbers, non-word characters, and extra spaces from text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\[[0-9]*\\]', ' ', text)  # Remove numbers\n",
    "    text = re.sub(r'\\W', ' ', text)          # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text)         # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "df['Findings_Value'] = df['Findings_Value'].apply(lambda x: preprocess_text(str(x)))\n",
    "\n",
    "# Tokenization and removal of stopwords\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    word_tokens = word_tokenize(sentence)  \n",
    "    return [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "df['Findings_Value'] = df['Findings_Value'].apply(remove_stopwords)\n",
    "\n",
    "# Preparing data for modeling\n",
    "X = df['Findings_Value']\n",
    "y = df['SEVERITY']\n",
    "\n",
    "# Text vectorization using Bag of Words and TF-IDF\n",
    "count_vect = CountVectorizer(min_df=1, max_df=1.0)\n",
    "X_counts = count_vect.fit_transform(X)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "# Label encoding\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Handling class imbalance with SMOTE and Edited Nearest Neighbours\n",
    "smote_enn = SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='all'))\n",
    "X_tfidf, y_new = smote_enn.fit_resample(X_tfidf, y_encoded)\n",
    "counterx = Counter(y_new)\n",
    "print('Class distribution:', counterx)\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_new, test_size=0.33, random_state=42)\n",
    "\n",
    "# Function to perform training and evaluation of a model\n",
    "def train_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Model Results:')\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Training and evaluating Random Forest, SVM, and XGBoost classifiers\n",
    "train_evaluate_model(RandomForestClassifier(), X_train, y_train, X_test, y_test)\n",
    "train_evaluate_model(LinearSVC(), X_train, y_train, X_test, y_test)\n",
    "train_evaluate_model(XGBClassifier(), X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Function to perform stratified 5-fold cross-validation\n",
    "def stratified_cross_validation(model, X, y):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "    print(f'5-Fold CV Scores: {scores}')\n",
    "    print(f'Average Score: {np.mean(scores):.2f}')\n",
    "\n",
    "# Stratified 5-fold cross-validation for Random Forest, SVM, and XGBoost classifiers\n",
    "stratified_cross_validation(RandomForestClassifier(random_state=42), X_tfidf, y_new)\n",
    "stratified_cross_validation(LinearSVC(), X_tfidf, y_new)\n",
    "stratified_cross_validation(XGBClassifier(), X_tfidf, y_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
